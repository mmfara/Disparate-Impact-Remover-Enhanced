{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORpEI29y4i5xJoQ75TleqJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmfara/Disparate-Impact-Remover-multiclass-repair/blob/main/Disparate_Impact_Remover__Modified_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHz_g9E2nH4I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import logging\n",
        "from aif360.algorithms import Transformer\n",
        "from itertools import product\n",
        "\n",
        "\n",
        "class DisparateImpactRemover(Transformer):\n",
        "    \"\"\"\n",
        "    Disparate Impact Remover that supports intersectional protected attributes.\n",
        "    Applies group-wise repair independently per intersectional group.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, repair_level=1.0, sensitive_attribute=None, min_group_size=20, verbose=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            repair_level (float): Degree of repair (0.0 = none, 1.0 = full).\n",
        "            sensitive_attribute (str or list): One or more protected attribute names.\n",
        "            min_group_size (int): Minimum number of samples in a group to apply repair.\n",
        "            verbose (bool): Enables logging if True.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        from BlackBoxAuditing.repairers.GeneralRepairer import Repairer\n",
        "        self.Repairer = Repairer\n",
        "\n",
        "        if not 0.0 <= repair_level <= 1.0:\n",
        "            raise ValueError(\"'repair_level' must be between 0.0 and 1.0.\")\n",
        "\n",
        "        if isinstance(sensitive_attribute, str):\n",
        "            self.sensitive_attributes = [sensitive_attribute]\n",
        "        elif isinstance(sensitive_attribute, list):\n",
        "            self.sensitive_attributes = sensitive_attribute\n",
        "        elif sensitive_attribute is None:\n",
        "            self.sensitive_attributes = []  # Will default to first from dataset\n",
        "        else:\n",
        "            raise TypeError(\"sensitive_attribute must be str, list, or None\")\n",
        "\n",
        "        self.repair_level = repair_level\n",
        "        self.min_group_size = min_group_size\n",
        "        self.verbose = verbose\n",
        "\n",
        "        if self.verbose:\n",
        "            logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "    def fit_transform(self, dataset):\n",
        "        # Default to first protected attribute if none provided\n",
        "        if not self.sensitive_attributes:\n",
        "            self.sensitive_attributes = dataset.protected_attribute_names[:1]\n",
        "\n",
        "        # Get column indices of protected attributes\n",
        "        indices = [dataset.feature_names.index(attr) for attr in self.sensitive_attributes]\n",
        "        protected_values = [np.unique(dataset.features[:, idx]) for idx in indices]\n",
        "\n",
        "        # All combinations of protected attribute values (intersectional groups)\n",
        "        group_combinations = list(product(*protected_values))\n",
        "\n",
        "        repaired = dataset.copy()\n",
        "        new_features = np.zeros_like(repaired.features)\n",
        "\n",
        "        for group_vals in group_combinations:\n",
        "            # Select rows that match the current group combination\n",
        "            mask = np.logical_and.reduce([\n",
        "                dataset.features[:, idx] == val for idx, val in zip(indices, group_vals)\n",
        "            ])\n",
        "\n",
        "            group_features = repaired.features[mask]\n",
        "\n",
        "            if group_features.shape[0] < self.min_group_size:\n",
        "                if self.verbose:\n",
        "                    logging.warning(f\"Skipping group {group_vals} (size={group_features.shape[0]})\")\n",
        "                new_features[mask] = group_features\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Pass one of the protected indices (any will do, group is already filtered)\n",
        "                repairer = self.Repairer(group_features.tolist(), indices[0], self.repair_level, False)\n",
        "                repaired_group_features = repairer.repair(group_features.tolist())\n",
        "                new_features[mask] = np.array(repaired_group_features)\n",
        "\n",
        "                if self.verbose:\n",
        "                    logging.info(f\"Repaired group {group_vals} (size={group_features.shape[0]})\")\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Repair failed for group {group_vals}: {e}\")\n",
        "                new_features[mask] = group_features  # fallback to original\n",
        "\n",
        "        # Restore protected attribute columns to ensure they remain unchanged\n",
        "        for idx in indices:\n",
        "            new_features[:, idx] = dataset.features[:, idx]\n",
        "\n",
        "        repaired.features = new_features\n",
        "        return repaired"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remover = DisparateImpactRemover(\n",
        "    repair_level=0.8,\n",
        "    sensitive_attribute=['gender', 'race'],\n",
        "    min_group_size=30,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "repaired_data = remover.fit_transform(dataset)"
      ],
      "metadata": {
        "id": "KR8D6OGRp6Ph"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}