{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFCFyLNQYbhS/KFIuloHRi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmfara/Disparate-Impact-Remover-multiclass-repair/blob/main/Disparate_Impact_Remover_Modified_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKeQ7VpPj_zr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from aif360.algorithms import Transformer\n",
        "\n",
        "class DisparateImpactRemover(Transformer):\n",
        "    \"\"\"\n",
        "    Modified Disparate Impact Remover that supports multi-valued protected attributes\n",
        "    by applying the repair process independently within each protected group.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, repair_level=1.0, sensitive_attribute=''):\n",
        "        super().__init__()  # âœ… Ensures compatibility with aif360.Transformer\n",
        "\n",
        "        from BlackBoxAuditing.repairers.GeneralRepairer import Repairer\n",
        "        self.Repairer = Repairer\n",
        "\n",
        "        if not 0.0 <= repair_level <= 1.0:\n",
        "            raise ValueError(\"'repair_level' must be between 0.0 and 1.0.\")\n",
        "\n",
        "        self.repair_level = repair_level\n",
        "\n",
        "        # Support string or list of sensitive attributes (default: 1)\n",
        "        if isinstance(sensitive_attribute, list):\n",
        "            self.sensitive_attribute = sensitive_attribute[0]  # Only one supported for now\n",
        "        else:\n",
        "            self.sensitive_attribute = sensitive_attribute\n",
        "\n",
        "    def fit_transform(self, dataset):\n",
        "        if not self.sensitive_attribute:\n",
        "            self.sensitive_attribute = dataset.protected_attribute_names[0]\n",
        "\n",
        "        index = dataset.feature_names.index(self.sensitive_attribute)\n",
        "        unique_groups = np.unique(dataset.features[:, index])\n",
        "\n",
        "        repaired = dataset.copy()\n",
        "        new_features = np.zeros_like(repaired.features)\n",
        "\n",
        "        for val in unique_groups:\n",
        "            group_mask = dataset.features[:, index] == val\n",
        "            group_features = repaired.features[group_mask]\n",
        "\n",
        "            # Apply repair only to non-protected attributes\n",
        "            repairer = self.Repairer(group_features.tolist(), index, self.repair_level, False)\n",
        "            repaired_group_features = repairer.repair(group_features.tolist())\n",
        "\n",
        "            new_features[group_mask] = np.array(repaired_group_features)\n",
        "\n",
        "        # Overwrite features in the repaired dataset\n",
        "        repaired.features = new_features\n",
        "\n",
        "        # Ensure protected attribute column remains unchanged\n",
        "        repaired.features[:, index] = dataset.features[:, index]\n",
        "\n",
        "        return repaired\n",
        "\n",
        "\n",
        "# Applying DisparateImpactRemover\n",
        "dir = DisparateImpactRemover(repair_level=0.8, sensitive_attribute=\"group\")"
      ]
    }
  ]
}